{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3df636d2",
   "metadata": {},
   "source": [
    "**Project Automated-Customer Reviews**\n",
    "\n",
    "**- This is the phase 3 of this project**<br>\n",
    "\n",
    "\"<i><i>Bla, Bla, Bla text.\n",
    "\n",
    "</i>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7b499a",
   "metadata": {},
   "source": [
    "**BART**<br>\n",
    "gpt copy, seems alright but have to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b68ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Imports and Setup (UPDATED)\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import numpy as np \n",
    "\n",
    "# Define constants for file names and the specific AI model\n",
    "SENTIMENT_FILE = 'sentiment_analysis_output.csv'\n",
    "CLUSTERING_FILE = 'clustering_output.csv'\n",
    "\n",
    "# **Update to target the BART model**\n",
    "# BART is commonly used with the 'facebook/bart-large-cnn' checkpoint for summarization.\n",
    "BART_MODEL = 'facebook/bart-large-cnn' \n",
    "\n",
    "##PAY ATTENTION TO THIS!!!\n",
    "REQUIRED_COLUMNS = [\n",
    "    'ProductID',\n",
    "    'Product Name',\n",
    "    'Category',\n",
    "    'Brand',\n",
    "    'Ratings',\n",
    "    'Cluster',\n",
    "    'sentiment',\n",
    "    'reviews.text',\n",
    "]\n",
    "\n",
    "print(f\"Setup Complete. Targeting model: {BART_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebb99c0",
   "metadata": {},
   "source": [
    "**Data Loading and prep**<br>#ADD PATHS FOR CSV FILES HERE!!!! BELOW!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531dee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Function to Load and Merge Data\n",
    "\n",
    "def load_and_merge_data():\n",
    "    \"\"\"Loads and merges sentiment and clustering data.\"\"\"\n",
    "    print(\"--- 1. Loading and Merging Data ---\")\n",
    "    try:\n",
    "        #ADD PATHS FOR CSV FILES HERE!!!! BELOW!!!\n",
    "        df_sentiment = pd.read_csv(SENTIMENT_FILE)\n",
    "        df_clustering = pd.read_csv(CLUSTERING_FILE)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}. Please ensure the input CSV files exist.\")\n",
    "        return None\n",
    "\n",
    "    # **NOTE: Adjust the 'on' column name based on your actual data structure.**\n",
    "    df_merged = pd.merge(df_sentiment, df_clustering, on='review_id', how='inner')\n",
    "    \n",
    "    missing_cols = [col for col in REQUIRED_COLUMNS if col not in df_merged.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"ERROR: Merged DataFrame is missing required columns: {missing_cols}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Merged DataFrame shape: {df_merged.shape}\")\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae622bcb",
   "metadata": {},
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835542c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Function to Prepare AI Prompt\n",
    "\n",
    "def prepare_category_input(df_category, min_reviews=10, positive_threshold=0.7, negative_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Analyzes products in a single category and constructs a detailed input prompt \n",
    "    for the generative AI model based on the project requirements.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Calculate Average Sentiment and Identify Top/Worst Products\n",
    "    product_summary = df_category.groupby('product_id')['sentiment_score'].agg(['mean', 'count']).reset_index()\n",
    "    product_summary = product_summary[product_summary['count'] >= min_reviews]\n",
    "    \n",
    "    # Sort and select Top 3 and Worst Product\n",
    "    product_summary = product_summary.sort_values(by='mean', ascending=False)\n",
    "    top_3 = product_summary.head(3)['product_id'].tolist()\n",
    "    \n",
    "    if product_summary.shape[0] < 4:\n",
    "        return None, f\"Only found {product_summary.shape[0]} products with more than {min_reviews} reviews.\"\n",
    "\n",
    "    worst_product = product_summary.tail(1)['product_id'].iloc[0]\n",
    "\n",
    "    # 2. Build the Multi-Part Prompt\n",
    "    category_name = df_category['product_category'].iloc[0]\n",
    "    prompt_sections = [\n",
    "        f\"Generate a compelling, well-structured blog article recommending products in the '{category_name}' category. \"\n",
    "        \"The article MUST detail the Top 3, highlight key differences, list primary complaints for the Top 3, and explain why the Worst Product should be avoided, based ONLY on the provided review data.\"\n",
    "    ]\n",
    "\n",
    "    # --- Section A & B: Top 3 Products, Features, and Complaints ---\n",
    "    \n",
    "    for rank, product_id in enumerate(top_3):\n",
    "        df_product_pos = df_category[(df_category['product_id'] == product_id) & (df_category['sentiment_score'] >= positive_threshold)]\n",
    "        df_product_neg = df_category[(df_category['product_id'] == product_id) & (df_category['sentiment_score'] <= negative_threshold)]\n",
    "        \n",
    "        meta_features = df_product_pos.groupby('meta_category')['review_text'].head(3).str.cat(sep=\" | \").replace('\\n', ' ')\n",
    "        complaint_texts = df_product_neg['review_text'].head(5).str.cat(sep=\" | \").replace('\\n', ' ')\n",
    "        \n",
    "        prompt_sections.append(\n",
    "            f\"\\n\\n--- Product #{rank+1} (Top Rated): {product_id} ---\"\n",
    "            f\"\\nCore Strengths (Clustered Reviews): {meta_features}\"\n",
    "            f\"\\nTop Complaints/Weaknesses: {complaint_texts}\"\n",
    "        )\n",
    "\n",
    "    # --- Section C: Worst Product to Avoid ---\n",
    "    df_worst = df_category[(df_category['product_id'] == worst_product)]\n",
    "    worst_neg_texts = df_worst[(df_worst['sentiment_score'] <= negative_threshold)]['review_text'].head(5).str.cat(sep=\" | \").replace('\\n', ' ')\n",
    "\n",
    "    prompt_sections.append(\n",
    "        f\"\\n\\n--- Product to AVOID: {worst_product} (Lowest Rated) ---\"\n",
    "        f\"\\nKey Negative Reviews/Reasons to Avoid: {worst_neg_texts}\"\n",
    "    )\n",
    "\n",
    "    final_prompt = \"\\n\".join(prompt_sections)\n",
    "    \n",
    "    return category_name, final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4386782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Function for Generative AI (BART) - REFORMULATED\n",
    "\n",
    "def generate_article_bart(prompt):\n",
    "    \"\"\"Uses the specified BART model to generate the structured article.\"\"\"\n",
    "    \n",
    "    # NOTE: BART is very good at summarization, but it may struggle to follow \n",
    "    # the multi-part structure of the long prompt as precisely as FLAN-T5 did.\n",
    "    print(f\"  -> Generating with {BART_MODEL} (Running on CPU)...\")\n",
    "    \n",
    "    try:\n",
    "        # We use the 'summarization' pipeline, which is common for BART models.\n",
    "        generator = pipeline(\n",
    "            \"summarization\", \n",
    "            model=BART_MODEL, \n",
    "            device='cpu'  # Explicitly use CPU\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR: Could not load model {BART_MODEL}. Check installation/path.\")\n",
    "        print(f\"  Error details: {e}\")\n",
    "        return \"MODEL LOADING FAILED\"\n",
    "\n",
    "    # Generate the article\n",
    "    # BART is trained to take long input and produce shorter output.\n",
    "    result = generator(\n",
    "        prompt, \n",
    "        max_length=500,  \n",
    "        min_length=150, \n",
    "        do_sample=True,  \n",
    "        temperature=0.7 \n",
    "    )\n",
    "    \n",
    "    return result[0]['summary_text'] # Output key for summarization pipeline is 'summary_text'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969963ee",
   "metadata": {},
   "source": [
    "**5: Main Execution Block**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecb466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Main Execution Block\n",
    "\n",
    "def main_article_generator():\n",
    "    \"\"\"Main function to execute the full template process.\"\"\"\n",
    "    \n",
    "    df_merged = load_and_merge_data()\n",
    "    \n",
    "    if df_merged is None:\n",
    "        return\n",
    "\n",
    "    # Group by the main product category\n",
    "    grouped_by_category = df_merged.groupby('product_category')\n",
    "    \n",
    "    print(\"\\n--- 2. Generating Articles by Category ---\")\n",
    "    \n",
    "    final_articles = {}\n",
    "    \n",
    "    # Iterate over each distinct product category\n",
    "    for category_name, df_category in grouped_by_category:\n",
    "        \n",
    "        print(f\"\\nProcessing Category: {category_name}\")\n",
    "        \n",
    "        # 1. Prepare the highly structured input prompt\n",
    "        category_name, ai_prompt = prepare_category_input(df_category)\n",
    "        \n",
    "        if ai_prompt.startswith(\"Only found\"):\n",
    "            print(f\"  Skipping category: {category_name}. {ai_prompt}\")\n",
    "            continue\n",
    "\n",
    "        # 2. Call the Generative Model\n",
    "        article = generate_article_flan(ai_prompt)\n",
    "        \n",
    "        final_articles[category_name] = article\n",
    "        \n",
    "        print(f\"âœ… Article Generated for: {category_name}\")\n",
    "\n",
    "    print(\"\\n--- Process Complete. Final Articles: ---\")\n",
    "    \n",
    "    # Final Output Display\n",
    "    for category, article in final_articles.items():\n",
    "        print(f\"\\n=====================================\")\n",
    "        print(f\"GENERATED ARTICLE: {category}\")\n",
    "        print(f\"=====================================\")\n",
    "        print(article)\n",
    "    \n",
    "    return final_articles\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == '__main__':\n",
    "    generated_articles = main_article_generator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiagoversion (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
