{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50a462d5",
   "metadata": {},
   "source": [
    "# Goal of Phase 3 - BART Implementation (Simplified)\n",
    "\n",
    "## Input\n",
    "A CSV file (`final.csv`) containing product information and reviews, with columns such as:\n",
    "\n",
    "- `ProductID`, `Product Name`, `Category`, `Brand`, `Ratings`\n",
    "- `sentiment` (positive/negative or numerical score)\n",
    "- `reviews.text`\n",
    "\n",
    "## Processing\n",
    "For each product category:\n",
    "\n",
    "1. Determine the **Top 3 products overall** based on average sentiment.  \n",
    "2. Identify the **worst product** in the category (lowest average sentiment).\n",
    "\n",
    "## AI Prompt Construction\n",
    "Create a structured, multi-part prompt instructing the AI to:\n",
    "\n",
    "- Recommend the Top 3 products with key differences.  \n",
    "- Explain why the worst product should be avoided.  \n",
    "- Base all insights **solely on the review data**.\n",
    "\n",
    "## Output\n",
    "- Use **BART** (`facebook/bart-large-cnn`) to generate a **human-readable blog-style article** per category.  \n",
    "- Save all articles in a CSV (`generated_articles_bart.csv`) with co\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddaec3d",
   "metadata": {},
   "source": [
    "### 1. Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be27528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"../outputs/final.csv\")\n",
    "\n",
    "# Map sentiment to numeric if needed\n",
    "sentiment_map = {\"positive\": 1, \"neutral\": 0, \"negative\": -1}\n",
    "if df['sentiment'].dtype == object:\n",
    "    df['sentiment_score'] = df['sentiment'].map(sentiment_map)\n",
    "else:\n",
    "    df['sentiment_score'] = df['sentiment']\n",
    "\n",
    "# Optional: remove duplicates\n",
    "df = df.drop_duplicates(subset=[\"ProductID\", \"reviews.text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30c7feb",
   "metadata": {},
   "source": [
    "### 2. Determine Top & Worst Products per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c45e493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by product\n",
    "product_avg_sentiment = (\n",
    "    df.groupby(['Cluster', 'ProductID', 'Product Name'])\n",
    "      .agg(avg_sentiment=('sentiment_score', 'mean'),\n",
    "           reviews=('reviews.text', lambda x: ' '.join(x)))\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Get top 3 and worst per cluster\n",
    "top_worst_per_cluster = {}\n",
    "for cluster, group in product_avg_sentiment.groupby('Cluster'):\n",
    "    top3 = group.sort_values('avg_sentiment', ascending=False).head(3)\n",
    "    worst = group.sort_values('avg_sentiment', ascending=True).head(1)\n",
    "    top_worst_per_cluster[cluster] = {\"top3\": top3, \"worst\": worst}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f1c71e",
   "metadata": {},
   "source": [
    "### 3. Construct AI Prompts for BART\n",
    "\n",
    "We want a structured prompt that:\n",
    "\n",
    "- Introduces the category\n",
    "\n",
    "- Lists Top 3 products & their key differences\n",
    "\n",
    "- Explains the worst product\n",
    "\n",
    "- Only uses review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39f191b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_bart_input(top3_df, worst_df):\n",
    "    \"\"\"\n",
    "    Concatenate all review texts for Top 3 and Worst product to feed BART.\n",
    "    \"\"\"\n",
    "    reviews_text = \"\"\n",
    "    \n",
    "    # Top 3 products\n",
    "    reviews_text += \"Top 3 products reviews:\\n\"\n",
    "    for i, row in top3_df.iterrows():\n",
    "        reviews_text += f\"{i+1}. {row['Product Name']}: {row['reviews']}\\n\\n\"\n",
    "    \n",
    "    # Worst product\n",
    "    worst_row = worst_df.iloc[0]\n",
    "    reviews_text += f\"Worst product review:\\n{worst_row['Product Name']}: {worst_row['reviews']}\\n\\n\"\n",
    "    \n",
    "    return reviews_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c68333",
   "metadata": {},
   "source": [
    "### 4. Generate Summury Using BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7cd7d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# Load BART\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "def generate_article(text):\n",
    "    \"\"\"\n",
    "    Generate a human-readable summary for the concatenated reviews.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, max_length=1024, return_tensors=\"pt\", truncation=True)\n",
    "    summary_ids = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        num_beams=4,\n",
    "        max_length=512,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1748c2",
   "metadata": {},
   "source": [
    "### 5. Loop over clusters and save CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b14a8731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles generated and saved to ../deliverables/generated_articles_bart.csv\n"
     ]
    }
   ],
   "source": [
    "articles = []\n",
    "\n",
    "for cluster, data in top_worst_per_cluster.items():\n",
    "    # Concatenate all reviews for Top 3 + Worst\n",
    "    bart_input_text = construct_bart_input(data['top3'], data['worst'])\n",
    "    \n",
    "    # Generate blog-style article using BART\n",
    "    article_text = generate_article(bart_input_text)\n",
    "    \n",
    "    # Store result\n",
    "    articles.append({\"Cluster\": cluster, \"Article\": article_text})\n",
    "\n",
    "# Save to CSV\n",
    "articles_df = pd.DataFrame(articles)\n",
    "articles_df.to_csv(\"../deliverables/generated_articles_bart.csv\", index=False)\n",
    "\n",
    "print(\"Articles generated and saved to ../deliverables/generated_articles_bart.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvSofia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
